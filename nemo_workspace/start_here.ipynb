{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3f0142-7447-497f-bb74-91bac8c93eb2",
   "metadata": {},
   "source": [
    "# NeMo Challenge Bootcamp\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024f281-3fb9-44e4-ae8b-db22daed31da",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The NeMo Challenge Bootcamp is designed from a real-world perspective, following the data processing, development, and deployment pipeline paradigm. Attendees walk through the workflow of preprocessing a multi-turn conversational dataset for the summarization task and fine-tune the dataset on SOTA LLM using NeMo-Run. Attendees will also learn to optimize the fine-tuned model and apply prompt engineering techniques to solve complex real-world tasks. Furthermore, we introduced an AI Assistant customer care use case challenge to test attendees' understanding of the material and solidify their experience in the Text Generation domain.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380ca5e-4fcb-466b-8a1b-1985f11feef6",
   "metadata": {},
   "source": [
    "### Why NeMo Challenge Bootcamp?\n",
    "\n",
    " Recently, the world has witnessed tremendous improvement and application of Large Language Models (LLMs). One way to get equipped and develop solutions powered by LLM is to get acquainted with an easy-to-use accelerated AI framework that enables an End-to-End paradigm fit for an enterprise solution. Such a framework is the NVIDIA NeMo. With the NeMo challenge Bootcamp, learners are equipped with knowledge that drives solutions to real-world use cases.\n",
    "\n",
    "The table of contents below will walk you through summarization dataset preprocessing, fine-tuning on Llama-3.1-8B, and running inference via NeMo Run. The Labs also include class activities to test your understanding of the concept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e5328-7563-402d-8773-981a9e548b29",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "The following contents will be covered:\n",
    "\n",
    "- Lab 1: [Preprocessing Multi-turn Conversational Dataset](jupyter_notebook/data-preprocessing.ipynb)\n",
    "- Lab 2: [Building a Text Summarization Model With NeMo-Run](jupyter_notebook/finetuning.ipynb)\n",
    "- Lab 3: [Prompt Engineering Techniques and Test-time Scaling (TTS)](jupyter_notebook/prompt-engineering.ipynb)\n",
    "- Lab 4: [Challenge](jupyter_notebook/challenge.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc39cae-d6d6-4c0b-8c00-f54cc08b5a4f",
   "metadata": {},
   "source": [
    "### Tutorial Duration\n",
    "The material will be presented in a total of 3 hours and 30 minutes. The Challenge part will take a maximum of 6 hours.\n",
    "\n",
    "### Content Level\n",
    "Advanced\n",
    "\n",
    "### Target Audience and Prerequisites\n",
    "The target audience for these labs is researchers, enterprises, and developers interested in applying LLM to solve their use cases via an accelerated AI framework. Audiences are expected to have background Knowledge of Python programming, PyTorch, and the fundamentals of large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61a4de-ff02-48a2-9c3f-aa1a36b3ab80",
   "metadata": {},
   "source": [
    "---\n",
    "### Licensing\n",
    "Copyright Â© 2025 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
